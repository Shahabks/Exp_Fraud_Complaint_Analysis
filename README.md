# Exp_Fraud_Complaint_Analysis
Set up an experiment to compare supervised to unsupervised (done by my colleague) Fraud-Complaint text analysis deploying BERT model. No doubt that the supervised learning was improved using the labeled data, the supervised model has better Precision and Recall (0.86, 0.91) on true positives (fraud cases) than the Unsupervised one (0.52 and 0.72 respectively).

![Image](https://github.com/Shahabks/Exp_Fraud_Complaint_Analysis/blob/master/wqawsqw.png)

### Note
Fraudulent activities are usually prosecuted, therefore fraudsters need to be creative and come up constantly with new ways of performing fraud. Furthermore, frauds are scarce (fortunately), and so we have few positive class patterns available for training. Because of these facts, it might make sense to build an unsupervised fraud detector. Using **only the training data**, create an anomaly detection model. one should also choose an error metric adequate for the problem, and tune the model parameters in order to optimize this error.
